---
citekey: "bigdely-shamloPREPPipelineStandardized2015"
title: "The PREP pipeline: standardized preprocessing for large-scale EEG analysis"
itemType: "journalArticle"
publicationTitle: "Frontiers in Neuroinformatics"
bookTitle: ""
seriesTitle: ""
publisher: ""
place: ""
volume: "9"
numberOfVolumes: ""
issue: ""
pages: ""
edition: ""
date: "2015-06-18"
DOI: "10.3389/fninf.2015.00016"
ISBN: ""
ISSN: "1662-5196"
url: "https://www.frontiersin.org/journals/neuroinformatics/articles/10.3389/fninf.2015.00016/full"
importance: 
status: incomplete
tags:
  - article
---

## The PREP pipeline: standardized preprocessing for large-scale EEG analysis

### Table of Contents

- [Annotations](#annotations)

+ [Commentaries](#commentaries)

- [Appendix](#appendix)

### Annotations


No annotations available.


### Notes


No notes available.


%% begin notes %%

<!-- Write your personal notes here -->

%% end notes %%

## Appendix

### Authors


- [[Nima Bigdely-Shamlo]] (author)

- [[Tim Mullen]] (author)

- [[Christian Kothe]] (author)

- [[Kyung-Min Su]] (author)

- [[Kay A. Robbins]] (author)



### Abstract

<p>The technology to collect brain imaging and physiological measures has become portable and ubiquitous, opening the possibility of large-scale analysis of real-world human imaging. By its nature, such data is large and complex, making automated processing essential. This paper shows how lack of attention to the very early stages of an EEG preprocessing pipeline can reduce the signal-to-noise ratio and introduce unwanted artifacts into the data, particularly for computations done in single precision. We demonstrate that ordinary average referencing improves the signal-to-noise ratio, but that noisy channels can contaminate the results. We also show that identification of noisy channels depends on the reference and examine the complex interaction of filtering, noisy channel identification, and referencing. We introduce a multi-stage robust referencing scheme to deal with the noisy channel-reference interaction. We propose a standardized early-stage EEG processing pipeline (PREP) and discuss the application of the pipeline to more than 600 EEG datasets. The pipeline includes an automatically generated report for each dataset processed. Users can download the PREP pipeline as a freely available MATLAB library from <ext-link ext-link-type="uri" xlink:href="http://eegstudy.org/prepcode" xmlns:xlink="http://www.w3.org/1999/xlink">http://eegstudy.org/prepcode</ext-link>.</p>


### Formatted Bibliography

Bigdely-Shamlo, N., Mullen, T., Kothe, C., Su, K.-M., & Robbins, K. A. (2015). The PREP pipeline: Standardized preprocessing for large-scale EEG analysis. _Frontiers in Neuroinformatics_, _9_. [https://doi.org/10.3389/fninf.2015.00016](https://doi.org/10.3389/fninf.2015.00016)


### Tags


- #eeg

- #preprocessing

- #artifact

- #bcilab

- #big_data

- #eeglab

- #machine_learning




### Attachments


- **Bigdely-Shamlo et al. - 2015 - The PREP pipeline standardized preprocessing for large-scale EEG analysis.pdf**: I:\My Drive\literature\neuro\Bigdely-Shamlo et al. - 2015 - The PREP pipeline standardized preprocessing for large-scale EEG analysis.pdf




### Collections


- neuro

- prepoc





### Backlinking


#### Metadata Links


- publicationTitle: [[Frontiers in Neuroinformatics]]




- date: [[2015]]





<!-- Any additional notes or comments -->


%% Import Date: 2025-01-09T18:09:14.351+00:00 %%
