---
title: "Analyzing Neural Time Series Data: Theory and Practice"
itemType: "book"
publicationTitle: ""
bookTitle: ""
seriesTitle: ""
publisher: "The MIT Press"
place: ""
volume: ""
numberOfVolumes: ""
issue: ""
pages: ""
edition: ""
date: "2014-01-17"
DOI: ""
ISBN: "978-0-262-31955-3"
ISSN: ""
url: "https://direct.mit.edu/books/monograph/4013/Analyzing-Neural-Time-Series-DataTheory-and"
importance: 
status: incomplete
tags:
  - article
---

## Analyzing Neural Time Series Data: Theory and Practice

### Table of Contents

- [Annotations](#annotations)

+ [Commentaries](#commentaries)

- [Appendix](#appendix)

### Annotations




#### Page 88







> From a convenience-of-analysis perspective, 1000 Hz is the optimal sampling rate.





- **Color**: #ff6666 (Red)
- **Date**: 2024-10-29 3:46 pm

---







> At 1000 Hz, there is a one-to-one conversion between time in milliseconds and time in samples. That is, 14 ms is also 14 samples. 500 and 2000 Hz are the next-most convenient sampling rates (14 ms is, respectively, 7 and 28 samples).





- **Color**: #ffd400 (Yellow)
- **Date**: 2024-10-29 3:46 pm

---



#### Page 89








> [[Response EMG]]





- **Color**: #5fb236 (Green)
- **Date**: 2024-10-29 3:46 pm

---








> [[force grips]]





- **Color**: #5fb236 (Green)
- **Date**: 2024-10-29 3:46 pm

---








> [[Eye tracker]]





- **Color**: #5fb236 (Green)
- **Date**: 2024-10-29 3:47 pm

---



#### Page 94







> Preprocessing Steps Necessary and Useful for Advanced Data Analysis





- **Color**: #aaaaaa (Gray)
- **Date**: 2024-10-29 3:48 pm

---



#### Page 97








> [[edge artifacts]]





- **Color**: #5fb236 (Green)
- **Date**: 2024-10-29 4:09 pm

---



#### Page 99




![](<0 - Supplementary/images/cohenAnalyzingNeuralTime2014.md/image-99-x110-y365.png>)



> *(No annotated text)*




- **Color**: #ffd400 (Yellow)
- **Date**: 2024-10-29 4:10 pm

---



#### Page 104




![](<0 - Supplementary/images/cohenAnalyzingNeuralTime2014.md/image-104-x44-y427.png>)



> *(No annotated text)*




- **Color**: #ffd400 (Yellow)
- **Date**: 2024-10-29 4:12 pm

---








> [[Earlobes]]





- **Color**: #5fb236 (Green)
- **Date**: 2024-10-29 4:12 pm

---



#### Page 106







> Preprocessing can help turn good data into very good data, but no amount of preprocessing will turn low-quality and noisy data into very good data.





- **Color**: #2ea8e5 (Blue)
- **Date**: 2024-10-29 4:13 pm

---







> Do not rush into a recording if you are unsatisfied with the data quality, and do not be afraid to pause the experiment if the data quality suddenly decreases during a recording and you think you can fix it. Explain to subjects (if they are human and awake) the importance of collecting clean data; they will try to help give you clean data.





- **Color**: #ffd400 (Yellow)
- **Date**: 2024-10-29 4:14 pm

---



#### Page 113








> [[EMG]]





- **Color**: #5fb236 (Green)
- **Date**: 2024-10-29 4:15 pm

---







> . EMG is noticeable as bursts of 20- to 40-Hz activity, often has relatively large amplitude, and is typically maximal in electrodes around the face, neck, and ears.





- **Color**: #ff6666 (Red)
- **Date**: 2024-10-29 4:15 pm

---







> EMG bursts are deleterious for EEG data if you plan on analyzing activity above 15 Hz.





- **Color**: #ff6666 (Red)
- **Date**: 2024-10-29 4:15 pm

---



#### Page 114




![](<0 - Supplementary/images/cohenAnalyzingNeuralTime2014.md/image-114-x58-y401.png>)



> *(No annotated text)*




- **Color**: #ffd400 (Yellow)
- **Date**: 2024-10-29 4:16 pm

---



#### Page 116







> Many EEG artifacts can therefore be minimized with proper training. After  setting up the EEG cap, show the subject her EEG data in real time on a computer monitor  that she can see. Explain that EEG data contain both brain activity and noise from muscles.  You can have her blink, clench her jaw, tense her neck/shoulder muscles, talk, smile, wiggle  her ears, and so on. When subjects know what kinds of behaviors produce EEG artifacts, they  can minimize those behaviors during the task.





- **Color**: #ffd400 (Yellow)
- **Date**: 2024-10-29 4:16 pm

---



#### Page 221







> Whereas the phase-angl–etime series from wavelet convolution or filter-Hilbert is an estimate of the instantaneous phase value at each time point, the  phase value from the short-time FFT method is the phase parameter of the sine wave at each  frequency





- **Color**: #ffd400 (Yellow)
- **Date**: 2024-12-18 7:03 pm

---








> [[intertrial phase clustering]]





- **Color**: #5fb236 (Green)
- **Date**: 2024-12-18 7:04 pm

---



#### Page 225




![](<0 - Supplementary/images/cohenAnalyzingNeuralTime2014.md/image-225-x106-y339.png>)



> *(No annotated text)*




- **Color**: #ffd400 (Yellow)
- **Date**: 2024-12-17 10:04 am

---



#### Page 226








> [[discrete prolate spheroidal sequences]]





- **Color**: #5fb236 (Green)
- **Date**: 2024-12-17 10:05 am

---








> [[Slepian tapers]]





- **Color**: #5fb236 (Green)
- **Date**: 2024-12-17 10:05 am

---







> Slepian tapers are orthogonal to each other (that is, the dot product of any one taper with any other taper is 0), and they have slightly different frequency characteristics, thus focusing the spectra of the resulting tapered time series on different parts of the spectrum.





- **Color**: #ff6666 (Red)
- **Date**: 2024-12-17 10:06 am

---



#### Page 228







> the Matlab toolbox fieldtrip has the most active development of this method, including, for example, options to create frequency-band-selective  tapers that further enhance their sensitivity beyond the basic multitaper application discussed in this chapter.





- **Color**: #ffd400 (Yellow)
- **Date**: 2024-12-17 10:08 am

---



#### Page 238







> Time-Frequency Power and Baseline Normalizations





- **Color**: #aaaaaa (Gray)
- **Date**: 2024-10-26 12:54 pm

---








> [[wavelet convolution]], [[filter-Hilbert]], [[short-window FFT]], [[multitap]]





- **Color**: #5fb236 (Green)
- **Date**: 2024-10-25 8:47 pm

---







> This is not specific to EEG data but also characterizes the relationship between power and frequency of many signals, including radio, radiation from the Big Bang, natural images, and many more.





- **Color**: #f19837 (Orange)
- **Date**: 2024-10-26 12:57 pm

---








> [[power law]]





- **Color**: #5fb236 (Green)
- **Date**: 2024-10-26 12:57 pm

---



#### Page 239







> The third limitation is that aggregating effects across subjects can be difficult with raw power values. This is because individual  differences in raw power are influenced by skull thickness, sulcal anatomy, cortical surface  area recruited, recording environment (e.g., scalp cleanliness and preparation and electrode  impedance), and other factors that are independent of the neurocognitive process under  investigation





- **Color**: #ff6666 (Red)
- **Date**: 2024-10-26 1:00 pm

---







> ). The fourth limitation is that taskrelated changes in power can be difficult to disentangle from background activity (this is also  shown below). This is particularly the case for frequencies that generally tend to have higher  power or frequencies that tend to have higher power during baseline periods, such as alpha  activity over posterior parietal and occipital electrode





- **Color**: #ff6666 (Red)
- **Date**: 2024-10-26 1:16 pm

---




![](<0 - Supplementary/images/cohenAnalyzingNeuralTime2014.md/image-239-x106-y389.png>)



> *(No annotated text)*




- **Color**: #ffd400 (Yellow)
- **Date**: 2024-10-26 12:58 pm

---



#### Page 240







> raw power values are not normally distributed because they cannot be negative and they are  strongly positively skewed. This limits the ability to apply parametric statistical analyses to  time-frequency power data.





- **Color**: #ff6666 (Red)
- **Date**: 2024-10-26 1:16 pm

---







> le, thef s1/hape  can be attenuated by taking the logarithm of the power values (Kiebel, Tallon-Baudry, and  Friston 2005)





- **Color**: #ffd400 (Yellow)
- **Date**: 2024-10-26 1:17 pm

---







> by modeling the 1/f shape and removing that fitted function from the data  (Freeman 2006).





- **Color**: #e56eee (Magenta)
- **Date**: 2024-10-26 1:17 pm

---




![](<0 - Supplementary/images/cohenAnalyzingNeuralTime2014.md/image-240-x49-y72.png>)



> *(No annotated text)*




- **Color**: #ffd400 (Yellow)
- **Date**: 2024-10-26 1:18 pm

---



#### Page 241




![](<0 - Supplementary/images/cohenAnalyzingNeuralTime2014.md/image-241-x114-y135.png>)



> *(No annotated text)*




- **Color**: #ff6666 (Red)
- **Date**: 2024-10-26 3:16 pm

---







> The horizontal bar over baseline indicates the mean across the baseline time period, and t  and f are time and frequency points. Note that the baseline has no t subscript, indicating that  all time points within a frequency band use the baseline perio





- **Color**: #ffd400 (Yellow)
- **Date**: 2024-10-26 2:42 pm

---



#### Page 242







> The baseline is a period of time, typically a few hundred milliseconds before the start of the trial, when little or no task-related processing is expected





- **Color**: #ff6666 (Red)
- **Date**: 2024-10-26 2:49 pm

---



#### Page 243







> data. Typical decibel values  after trial averaging are in the range of ±1–4 dB.





- **Color**: #ff6666 (Red)
- **Date**: 2024-10-26 2:54 pm

---







> do not transform each trial to decibels separately  and then average.





- **Color**: #ff6666 (Red)
- **Date**: 2024-10-26 2:54 pm

---







> No matter what color scale you use, you should always plot a color bar with numerical labels for the lower and upper color limits alongside the plots in your figures





- **Color**: #a28ae5 (Purple)
- **Date**: 2024-10-26 3:14 pm

---




![](<0 - Supplementary/images/cohenAnalyzingNeuralTime2014.md/image-243-x100-y333.png>)



> *(No annotated text)*




- **Color**: #ffd400 (Yellow)
- **Date**: 2024-10-26 2:44 pm

---



#### Page 244




![](<0 - Supplementary/images/cohenAnalyzingNeuralTime2014.md/image-244-x62-y147.png>)



> *(No annotated text)*




- **Color**: #ff6666 (Red)
- **Date**: 2024-10-26 3:16 pm

---







> A related transform to percentage change is dividing power during the task by power during the baseline time period.




**Comment**: Isn't this just the decibel conversion procedure but with less steps? How can this take care of the 1/f nature of power.


- **Color**: #e56eee (Magenta)
- **Date**: 2024-10-26 3:20 pm

---



#### Page 245




![](<0 - Supplementary/images/cohenAnalyzingNeuralTime2014.md/image-245-x90-y343.png>)



> *(No annotated text)*




- **Color**: #ff6666 (Red)
- **Date**: 2024-10-26 3:40 pm

---







> The Z-transform differs from decibel and  percentage change because the latter two methods are based only on the average baseline  power, whereas the Z-transform is based both on the average baseline power and on the standard deviation of the baseline power over time. Because of this, estimates of stimulus-related  power may be adversely affected by highly variable data in the baseline period. This may be  an issue if you have noisy data or few trials.





- **Color**: #ff6666 (Red)
- **Date**: 2024-10-26 3:23 pm

---



#### Page 246




![](<0 - Supplementary/images/cohenAnalyzingNeuralTime2014.md/image-246-x53-y124.png>)



> *(No annotated text)*




- **Color**: #ffd400 (Yellow)
- **Date**: 2024-10-26 3:40 pm

---



#### Page 247




![](<0 - Supplementary/images/cohenAnalyzingNeuralTime2014.md/image-247-x70-y264.png>)



> *(No annotated text)*




- **Color**: #ffd400 (Yellow)
- **Date**: 2024-10-26 3:48 pm

---



#### Page 248








> [[empirical mode decomposition]]





- **Color**: #5fb236 (Green)
- **Date**: 2024-10-26 2:58 pm

---








> [[Frobenius norm]]





- **Color**: #5fb236 (Green)
- **Date**: 2024-10-26 2:59 pm

---







> For time-frequency power, linear baseline subtractions should be  avoided because they do not address 1/f power-law scaling.





- **Color**: #ff6666 (Red)
- **Date**: 2024-10-26 2:59 pm

---







> First, power values cannot be negative, which means that the distribution of power values  across trials is likely to be positively skewed. Second, for the same reason, outliers and other  nonrepresentative data are more likely to be larger than the mean, compared to smaller  than the mean, and therefore will bias the mean toward larger values. This is further exacerbated by the fact that power is amplitude squared. Thus, somewhat large amplitude values  become larger power values, and very large amplitude values, which may be outliers, become  extremely large power values. Therefore, there is a danger that with a relatively low trial  count and noisy data, outliers in one condition can skew the results to incorrectly suggest a  condition difference (Handelsman 2002).





- **Color**: #ff6666 (Red)
- **Date**: 2024-10-26 3:51 pm

---



#### Page 249




![](<0 - Supplementary/images/cohenAnalyzingNeuralTime2014.md/image-249-x80-y398.png>)



> *(No annotated text)*



**Comment**: This can be used as a test to qualitatively assess the signal-to-noise ratio.


- **Color**: #ffd400 (Yellow)
- **Date**: 2024-10-26 3:54 pm

---



#### Page 250







> One situation in which the median might be preferred over the mean, or in addition to the  mean, is when there are few trials and noisy data.





- **Color**: #ff6666 (Red)
- **Date**: 2024-10-26 4:18 pm

---



#### Page 251







> Typically, power data are averaged across all trials, and then a baseline normalization is  applied. Performing baseline normalization on single trials prior to averaging helps minimize the influence of outlier trials but does not completely mitigate their impact, particularly for large outliers





- **Color**: #ff6666 (Red)
- **Date**: 2024-10-26 4:22 pm

---




![](<0 - Supplementary/images/cohenAnalyzingNeuralTime2014.md/image-251-x107-y389.png>)



> *(No annotated text)*




- **Color**: #ffd400 (Yellow)
- **Date**: 2024-10-26 4:21 pm

---



#### Page 252




![](<0 - Supplementary/images/cohenAnalyzingNeuralTime2014.md/image-252-x63-y242.png>)



> *(No annotated text)*



**Comment**: I could create a script that checks the consistency of the baseline normalized activity for different baselines. I would then choose as my baseline the one that gives more stable results.


- **Color**: #ffd400 (Yellow)
- **Date**: 2024-10-27 11:03 pm

---



#### Page 253







> Although in ERP analyses it is common to have the baseline end at time = 0, for timefrequency analyses this can be suboptimal because temporal smoothing from time-frequency  decomposition can produce some temporal leakage of trial-related activity to the pretrial  time period, particularly if the activity occurs shortly after the time = 0 event. Thus, a good  baseline time period might be –500 to –200 ms, or –400 to –100 ms.





- **Color**: #ff6666 (Red)
- **Date**: 2024-10-27 11:04 pm

---







> Because any activity present in the baseline period will be transferred to the task-related  activity, it is a good idea to use the pretrial period as a baseline even if you are not examining  stimulus-locked activity. For example, if there are multiple stimuli and a response in each  trial, and your hypotheses concern response-related activity, a preresponse baseline window  may include stimulus-related activity.





- **Color**: #ff6666 (Red)
- **Date**: 2024-10-27 11:07 pm

---



#### Page 254







> A pretrial baseline period is optimal. Whenever possible, try to design your experiment  such that a pretrial baseline period of several hundred milliseconds can be use





- **Color**: #a28ae5 (Purple)
- **Date**: 2024-10-27 11:13 pm

---







> There are three alternative options for baseline normalization that you could consider.




**Comment**: The following approaches are very interesting but all of them are only suitable for trial-based tasks. What should I do if I have few trials, and all of these radically different conditions? Shall I use a participant-averaged baseline?


- **Color**: #ffd400 (Yellow)
- **Date**: 2024-10-27 11:20 pm

---



#### Page 255








> [[Signal-to-noise ratio]]





- **Color**: #5fb236 (Green)
- **Date**: 2024-10-27 11:26 pm

---



#### Page 256







> For example, in the ERP literature, SNR is often estimated as the ratio of a component  peak voltage to the temporal variance during the pretrial baseline period. T





- **Color**: #ff6666 (Red)
- **Date**: 2024-10-27 11:27 pm

---




![](<0 - Supplementary/images/cohenAnalyzingNeuralTime2014.md/image-256-x64-y427.png>)



> *(No annotated text)*




- **Color**: #ff6666 (Red)
- **Date**: 2024-10-27 11:29 pm

---







> SNRtf can be useful for two reasons. First, it can be used to help determine the quality of  single-subject data when you are interpreting the robustness of a finding. That is, changes  in power over time, across electrodes, or among conditions can be considered robust if  the SNR is “big enough.




**Comment**: This is a topic of research that needs to be better researched.


- **Color**: #ffd400 (Yellow)
- **Date**: 2024-10-27 11:34 pm

---



#### Page 257




![](<0 - Supplementary/images/cohenAnalyzingNeuralTime2014.md/image-257-x92-y195.png>)



> *(No annotated text)*




- **Color**: #ffd400 (Yellow)
- **Date**: 2024-10-27 11:32 pm

---







> The second reason whySNRtf might be useful is in testing hypotheses about withinsubject, cross-trial variability.





- **Color**: #ffd400 (Yellow)
- **Date**: 2024-10-27 11:34 pm

---



#### Page 258








> [[error-related medial frontal theta]]





- **Color**: #5fb236 (Green)
- **Date**: 2024-10-27 11:41 pm

---







> One way to test whether you have enough trials is by estimating the reliability of the  trial-averaged power using random subsets of trials





- **Color**: #a28ae5 (Purple)
- **Date**: 2024-10-27 11:56 pm

---



#### Page 259




![](<0 - Supplementary/images/cohenAnalyzingNeuralTime2014.md/image-259-x87-y202.png>)



> *(No annotated text)*



**Comment**: This is a really good way to estimate sample size.


- **Color**: #a28ae5 (Purple)
- **Date**: 2024-10-27 11:56 pm

---








> [[Cronbach’s α]]





- **Color**: #5fb236 (Green)
- **Date**: 2024-10-27 11:58 pm

---







> Based on other measures of reliability (such as Cronbach’s α, for example), trial counts that  correspond to correlations of around 0.7 should provide a reasonable number of trials per  condition.





- **Color**: #ff6666 (Red)
- **Date**: 2024-10-27 11:58 pm

---



#### Page 260







> However, after time-frequency decomposition, the temporal precision decreases because the  estimate of power at each time point is a weighted combination of temporally surrounding time points. This means that activity from neighboring time points is autocorrelated  and thus provides redundant information. In other words, after time-frequency decomposition, the temporal resolution is greater than the temporal precision. Thus, you can often  downsample the results after the time-frequency decomposition with little or no loss of  information. In many cases the results can be downsampled to 40 or 50 Hz (that is, one  estimate of activity each 20 or 25 ms)





- **Color**: #ff6666 (Red)
- **Date**: 2024-10-28 12:00 am

---







> Furthermore, you should justify the reason for applying or not applying baseline normalization.





- **Color**: #a28ae5 (Purple)
- **Date**: 2024-10-28 12:02 am

---



#### Page 352







> For phase-based connectivity, you can use measures that are insensitive to volume  conduction such as imaginary coherence, phase-lag index, weighted phase-lag index, or  phase-slope-index.





- **Color**: #ff6666 (Red)
- **Date**: 2024-10-25 8:47 pm

---








> [[phase-based connectivity]]





- **Color**: #5fb236 (Green)
- **Date**: 2024-10-25 8:47 pm

---








> [[imaginary coherence]], [[phase-lag index]], [[weighted phase-lag index]]





- **Color**: #5fb236 (Green)
- **Date**: 2024-10-25 8:47 pm

---








> [[phase-slope-index]]





- **Color**: #5fb236 (Green)
- **Date**: 2024-10-25 8:47 pm

---



#### Page 367







> Because effects of volume conduction are instantaneous within measurement capabilities of  M/EEG acquisition and within frequencies typically investigated in M/EEG research (Plonsey  and Heppner 1967; Stinstra and Peters 1998), spurious connectivity results that are caused by  two electrodes measuring activity from the same source will have phase lags of zero or π (π if  the electrodes are on opposite sides of the dipole).





- **Color**: #ff6666 (Red)
- **Date**: 2024-10-25 8:47 pm

---





### Notes


No notes available.


%% begin notes %%

### Bookmark

- **Bookmark**: Page 217
- **Status**: #incomplete
- **Relevance**: 9.7
## Commentaries



%% end notes %%

## Appendix

### Authors


- [[Mike X. Cohen]] (author)



### Abstract

A comprehensive guide to the conceptual, mathematical, and implementational aspects of analyzing electrical brain signals, including data from MEG, EEG, an


### Formatted Bibliography

Cohen, M. X. (2014). _Analyzing Neural Time Series Data: Theory and Practice_. The MIT Press. [https://doi.org/10.7551/mitpress/9609.001.0001](https://doi.org/10.7551/mitpress/9609.001.0001)




### Attachments


- **PDF**: C:\Users\joaop\Zotero\storage\C3VYFTBS\Cohen - 2014 - Analyzing Neural Time Series Data Theory and Practice.pdf




### Collections


- books





### Backlinking


#### Metadata Links



- publisher: [[The MIT Press]]



- date: [[2014]]






%% Import Date: 2024-12-18T22:07:44.042+00:00 %%
